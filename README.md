# ğŸ“Š Dashboard de Credit Scoring â€“ Projet Data Science

## ğŸ¯ Contexte

Dans le cadre dâ€™un projet simulÃ© en environnement professionnel, jâ€™ai intÃ©grÃ© lâ€™Ã©quipe Data dâ€™une sociÃ©tÃ© financiÃ¨re fictive nommÃ©e **PrÃªt Ã  dÃ©penser**, spÃ©cialisÃ©e dans les crÃ©dits Ã  la consommation pour des profils sans historique de prÃªt.

AprÃ¨s avoir dÃ©veloppÃ© un **modÃ¨le de scoring crÃ©dit**, lâ€™objectif de cette mission a Ã©tÃ© de concevoir un **dashboard interactif**, clair et pÃ©dagogique, destinÃ© aux **chargÃ©s de relation client** afin de justifier les dÃ©cisions dâ€™octroi de crÃ©dit auprÃ¨s des clients.

---

## ğŸ§­ Objectifs fonctionnels

- Visualiser le **score de crÃ©dit** et la **probabilitÃ© associÃ©e** dâ€™un client (acceptÃ©/refusÃ©)
- Comparer ses **caractÃ©ristiques personnelles** avec la population gÃ©nÃ©rale ou un groupe filtrÃ©
- Fournir une **interprÃ©tation du score** via des explications locales (SHAP) et globales
- IntÃ©grer une **API REST** pour rÃ©cupÃ©rer le score dâ€™un client existant ou simuler un nouveau dossier
- Assurer la **comprÃ©hensibilitÃ© pour les non-experts**
- Respecter les standards dâ€™**accessibilitÃ©** (WCAG)
- DÃ©ployer le dashboard sur le **cloud (Streamlit Cloud)** pour accÃ¨s distant

---

## âš™ï¸ Stack technique

- **Python** : traitement, visualisation, API calls
- **Streamlit** : interface utilisateur interactive
- **Plotly / Matplotlib / Seaborn** : visualisations
- **XGBoost / Logistic Regression** : modÃ¨les de scoring
- **SHAP** : interprÃ©tation locale des prÃ©dictions
- **API** : Flask + Render pour prÃ©diction en ligne
- **HÃ©bergement** : Streamlit Cloud

---

## ğŸ“‚ Structure du projet

credit_scoring_dashboard/
â”‚
â”œâ”€â”€ app.py â† Code principal du dashboard Streamlit
â”œâ”€â”€ api_client.py â† RequÃªtes vers lâ€™API de scoring
â”œâ”€â”€ utils.py â† Fonctions dâ€™analyse et SHAP
â”œâ”€â”€ model/best_model.pkl â† ModÃ¨le de scoring entraÃ®nÃ©
â”œâ”€â”€ data/application_train.csv â† DonnÃ©es client (Ã©chantillon anonymisÃ©)
â”œâ”€â”€ assets/ â† Images, logos, et icÃ´nes
â””â”€â”€ README.md â† Ce fichier


# ğŸ§  Mini MoMi â€“ Veille Technique : NLP avec Modern BERT vs TF-IDF

## ğŸ¯ Objectif

Dans le cadre de ma mission de veille technique chez *PrÃªt Ã  dÃ©penser*, jâ€™ai Ã©tudiÃ© et comparÃ© une approche classique dâ€™analyse de texte (TF-IDF + rÃ©gression logistique) avec une mÃ©thode plus rÃ©cente basÃ©e sur **Modern BERT**, un modÃ¨le prÃ©-entraÃ®nÃ© de la famille des Transformers.

Lâ€™objectif : tester les performances et lâ€™interprÃ©tabilitÃ© de **Modern BERT** dans un contexte rÃ©el, en lâ€™appliquant aux donnÃ©es clients (commentaires, descriptions) utilisÃ©es dans nos projets de scoring ou de classification produit.

---

## ğŸ§ª MÃ©thodes comparÃ©es

| MÃ©thode | Description | ModÃ¨le | InterprÃ©tabilitÃ© | Temps dâ€™entraÃ®nement |
|--------|-------------|--------|------------------|----------------------|
| **TF-IDF** | Extraction manuelle de features | LogisticRegression | Bonne (coefficients) | Rapide |
| **Modern BERT** | Embeddings contextuels (transformer) | DistilBERT + MLP | Moyenne (via attention/SHAP) | Plus long |

---

## ğŸ”§ ImplÃ©mentation

- **DonnÃ©es** : texte client anonymisÃ© / jeu de classification public
- **PrÃ©traitement** : nettoyage, tokenisation
- **ModÃ¨le Modern BERT** : `distilbert-base-uncased` via HuggingFace Transformers
- **Ã‰valuation** : Accuracy, F1, temps de calcul, explications locales (SHAP)

---

## ğŸ“Œ RÃ©sultats observÃ©s

- ğŸ“ˆ BERT offre de meilleures performances sur des textes ambigus ou non structurÃ©s.
- âš™ï¸ TF-IDF reste plus rapide et plus transparent, utile pour des dÃ©ploiements rapides.
- ğŸ§  Les reprÃ©sentations de BERT permettent dâ€™intÃ©grer du contexte sÃ©mantique inaccessible avec TF-IDF.

## ğŸ”— RÃ©fÃ©rences

- [Devlin et al., 2018 â€“ BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/abs/1810.04805)  
- [HuggingFace Transformers](https://huggingface.co/transformers/)  
- [Papers with Code â€“]()
